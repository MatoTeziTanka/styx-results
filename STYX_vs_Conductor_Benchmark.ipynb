{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# STYX vs Conductor Benchmark\n",
        "\n",
        "**Purpose:** Compare token efficiency between STYX (Selective Token Yield eXtraction) and Google Conductor's context management approach.\n",
        "\n",
        "**Hypothesis:** STYX extracts only decision-relevant state, while Conductor stores full markdown context. STYX should use significantly fewer tokens for equivalent understanding.\n",
        "\n",
        "**Dataset:** facebook/react GitHub issues (287 issues from prior validation)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies\n",
        "!pip install tiktoken requests PyGithub -q"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration\n",
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# Get API key from Colab secrets (add your key in the Colab sidebar under 'Secrets')\n",
        "# Name it GEMINI_API_KEY\n",
        "try:\n",
        "    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')\n",
        "except:\n",
        "    GEMINI_API_KEY = input('Enter your Gemini API key: ')\n",
        "\n",
        "os.environ['GEMINI_API_KEY'] = GEMINI_API_KEY\n",
        "print(f'API key configured (length: {len(GEMINI_API_KEY)})')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "import requests\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Token counter (using cl100k_base, similar to GPT-4/Gemini tokenization)\n",
        "enc = tiktoken.get_encoding('cl100k_base')\n",
        "\n",
        "def count_tokens(text: str) -> int:\n",
        "    return len(enc.encode(text))\n",
        "\n",
        "print('Tokenizer loaded')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch GitHub issues (facebook/react)\n",
        "def fetch_github_issues(repo='facebook/react', max_issues=287):\n",
        "    issues = []\n",
        "    page = 1\n",
        "    while len(issues) < max_issues:\n",
        "        url = f'https://api.github.com/repos/{repo}/issues'\n",
        "        params = {'state': 'all', 'per_page': 100, 'page': page}\n",
        "        resp = requests.get(url, params=params)\n",
        "        if resp.status_code != 200:\n",
        "            print(f'GitHub API error: {resp.status_code}')\n",
        "            break\n",
        "        batch = resp.json()\n",
        "        if not batch:\n",
        "            break\n",
        "        issues.extend(batch)\n",
        "        page += 1\n",
        "        print(f'Fetched {len(issues)} issues...')\n",
        "    return issues[:max_issues]\n",
        "\n",
        "issues = fetch_github_issues()\n",
        "print(f'Total issues fetched: {len(issues)}')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# APPROACH 1: Full Context (baseline)\n",
        "# What you'd send if you just dumped everything\n",
        "\n",
        "full_context = '\\n\\n'.join([\n",
        "    f\"Issue #{i['number']}: {i['title']}\\nState: {i['state']}\\nLabels: {[l['name'] for l in i.get('labels', [])]}\\nBody: {i.get('body', '') or '(empty)'}\\n\"\n",
        "    for i in issues\n",
        "])\n",
        "\n",
        "full_tokens = count_tokens(full_context)\n",
        "print(f'Full context: {full_tokens:,} tokens')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# APPROACH 2: Conductor-style Context\n",
        "# Conductor stores context as structured markdown files\n",
        "# Simulating: product.md, techstack.md, style.md, and issue summaries\n",
        "\n",
        "conductor_product_md = '''# Product Context: React\n",
        "## Overview\n",
        "React is a JavaScript library for building user interfaces.\n",
        "\n",
        "## Goals\n",
        "- Declarative views\n",
        "- Component-based architecture\n",
        "- Learn once, write anywhere\n",
        "\n",
        "## Current Focus\n",
        "- React 19 features\n",
        "- Server Components\n",
        "- Concurrent rendering\n",
        "'''\n",
        "\n",
        "conductor_techstack_md = '''# Tech Stack\n",
        "- Language: JavaScript/TypeScript\n",
        "- Build: Rollup, Webpack\n",
        "- Testing: Jest\n",
        "- CI: GitHub Actions\n",
        "'''\n",
        "\n",
        "conductor_issues_md = '# Active Issues\\n\\n' + '\\n'.join([\n",
        "    f\"## Issue #{i['number']}: {i['title']}\\nState: {i['state']}\\nLabels: {[l['name'] for l in i.get('labels', [])]}\\nSummary: {(i.get('body', '') or '')[:500]}...\\n\"\n",
        "    for i in issues\n",
        "])\n",
        "\n",
        "conductor_context = conductor_product_md + '\\n' + conductor_techstack_md + '\\n' + conductor_issues_md\n",
        "conductor_tokens = count_tokens(conductor_context)\n",
        "print(f'Conductor-style context: {conductor_tokens:,} tokens')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# APPROACH 3: STYX Extraction\n",
        "# Extract only decision-relevant binding state\n",
        "\n",
        "def styx_extract(issues):\n",
        "    \"\"\"STYX: Selective Token Yield eXtraction\n",
        "    Extracts only decision-relevant state from issues.\n",
        "    Categories: decisions, constraints, tensions, anti_patterns\n",
        "    \"\"\"\n",
        "    decisions = []\n",
        "    constraints = []\n",
        "    tensions = []\n",
        "    anti_patterns = []\n",
        "    \n",
        "    decision_keywords = ['decided', 'will', 'must', 'should', 'approved', 'merged', 'accepted', 'implemented']\n",
        "    constraint_keywords = ['cannot', 'must not', 'blocked', 'requires', 'depends on', 'breaking change']\n",
        "    tension_keywords = ['vs', 'tradeoff', 'alternative', 'instead', 'conflict', 'disagree']\n",
        "    anti_pattern_keywords = ['don\\'t', 'avoid', 'deprecated', 'wrong', 'mistake', 'bug', 'regression']\n",
        "    \n",
        "    for issue in issues:\n",
        "        title = issue['title'].lower()\n",
        "        body = (issue.get('body', '') or '').lower()\n",
        "        labels = [l['name'].lower() for l in issue.get('labels', [])]\n",
        "        combined = title + ' ' + body\n",
        "        \n",
        "        # Extract decisions\n",
        "        if any(kw in combined for kw in decision_keywords) or 'decision' in labels:\n",
        "            decisions.append(f\"#{issue['number']}: {issue['title'][:100]}\")\n",
        "        \n",
        "        # Extract constraints\n",
        "        if any(kw in combined for kw in constraint_keywords) or 'breaking change' in labels:\n",
        "            constraints.append(f\"#{issue['number']}: {issue['title'][:100]}\")\n",
        "        \n",
        "        # Extract tensions\n",
        "        if any(kw in combined for kw in tension_keywords):\n",
        "            tensions.append(f\"#{issue['number']}: {issue['title'][:100]}\")\n",
        "        \n",
        "        # Extract anti-patterns\n",
        "        if any(kw in combined for kw in anti_pattern_keywords) or 'bug' in labels:\n",
        "            anti_patterns.append(f\"#{issue['number']}: {issue['title'][:100]}\")\n",
        "    \n",
        "    return {\n",
        "        'decisions': decisions,\n",
        "        'constraints': constraints,\n",
        "        'tensions': tensions,\n",
        "        'anti_patterns': anti_patterns\n",
        "    }\n",
        "\n",
        "styx_state = styx_extract(issues)\n",
        "\n",
        "styx_context = f'''# STYX Binding State\n",
        "## Decisions ({len(styx_state['decisions'])})\n",
        "{chr(10).join(styx_state['decisions'][:50]) if styx_state['decisions'] else 'None'}\n",
        "\n",
        "## Constraints ({len(styx_state['constraints'])})\n",
        "{chr(10).join(styx_state['constraints'][:20]) if styx_state['constraints'] else 'None'}\n",
        "\n",
        "## Tensions ({len(styx_state['tensions'])})\n",
        "{chr(10).join(styx_state['tensions'][:30]) if styx_state['tensions'] else 'None'}\n",
        "\n",
        "## Anti-Patterns ({len(styx_state['anti_patterns'])})\n",
        "{chr(10).join(styx_state['anti_patterns'][:20]) if styx_state['anti_patterns'] else 'None'}\n",
        "'''\n",
        "\n",
        "styx_tokens = count_tokens(styx_context)\n",
        "print(f'STYX context: {styx_tokens:,} tokens')\n",
        "print(f'\\nExtracted: {len(styx_state[\"decisions\"])} decisions, {len(styx_state[\"constraints\"])} constraints, {len(styx_state[\"tensions\"])} tensions, {len(styx_state[\"anti_patterns\"])} anti-patterns')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RESULTS COMPARISON\n",
        "print('=' * 60)\n",
        "print('STYX vs CONDUCTOR BENCHMARK RESULTS')\n",
        "print('=' * 60)\n",
        "print(f'Dataset: facebook/react ({len(issues)} issues)')\n",
        "print(f'Date: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
        "print('=' * 60)\n",
        "print(f'{\"Approach\":<25} {\"Tokens\":>12} {\"vs Full\":>12} {\"vs Conductor\":>15}')\n",
        "print('-' * 60)\n",
        "print(f'{\"Full Context (baseline)\":<25} {full_tokens:>12,} {\"1.0x\":>12} {\"-\":>15}')\n",
        "print(f'{\"Conductor-style\":<25} {conductor_tokens:>12,} {full_tokens/conductor_tokens:>11.1f}x {\"-\":>15}')\n",
        "print(f'{\"STYX\":<25} {styx_tokens:>12,} {full_tokens/styx_tokens:>11.1f}x {conductor_tokens/styx_tokens:>14.1f}x')\n",
        "print('=' * 60)\n",
        "print(f'\\nSTYX achieves {100 - (styx_tokens/full_tokens*100):.1f}% token reduction vs full context')\n",
        "print(f'STYX achieves {100 - (styx_tokens/conductor_tokens*100):.1f}% token reduction vs Conductor')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results for evidence\n",
        "results = {\n",
        "    'benchmark': 'STYX vs Conductor',\n",
        "    'dataset': 'facebook/react',\n",
        "    'issues_count': len(issues),\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'results': {\n",
        "        'full_context_tokens': full_tokens,\n",
        "        'conductor_tokens': conductor_tokens,\n",
        "        'styx_tokens': styx_tokens,\n",
        "        'styx_vs_full_ratio': round(full_tokens/styx_tokens, 2),\n",
        "        'styx_vs_conductor_ratio': round(conductor_tokens/styx_tokens, 2),\n",
        "        'styx_reduction_vs_full_pct': round(100 - (styx_tokens/full_tokens*100), 1),\n",
        "        'styx_reduction_vs_conductor_pct': round(100 - (styx_tokens/conductor_tokens*100), 1)\n",
        "    },\n",
        "    'styx_extraction': {\n",
        "        'decisions': len(styx_state['decisions']),\n",
        "        'constraints': len(styx_state['constraints']),\n",
        "        'tensions': len(styx_state['tensions']),\n",
        "        'anti_patterns': len(styx_state['anti_patterns'])\n",
        "    }\n",
        "}\n",
        "\n",
        "with open('styx_vs_conductor_results.json', 'w') as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print('Results saved to styx_vs_conductor_results.json')\n",
        "print(json.dumps(results, indent=2))"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}